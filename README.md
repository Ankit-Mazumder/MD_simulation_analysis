Spatio-Temporal Graph Transformer for Molecular Dynamics
========================================================

A hybrid Deep Learning framework combiningÂ **Graph Neural Networks (GINEConv)**Â withÂ **Temporal Transformers**Â to predict thermodynamic properties (specifically Gibbs Free Energy,Â $\Delta G$) from Molecular Dynamics (MD) simulation trajectories.

This model captures both theÂ **spatial geometry**Â of atoms within a single frame and theÂ **temporal evolution**Â of the system across a sliding time window.

ğŸ§  Model Architecture
---------------------

The model processes sequential windows of molecular graphs (frames) to predict a single scalar value for the window.

### Data Flow Pipeline

1.  **Input:**Â A window ofÂ $T$Â frames (defaultÂ $T=5$). Each frame is a graphÂ $G = (V, E)$.

2.  **Spatial Encoding (GNN):**Â * 3 layers ofÂ **GINEConv**Â (Graph Isomorphism Network with Edge features).

    -   Extracts atomic interactions and local geometry.

3.  **Global Pooling:**Â Aggregates node features into a single vector per frame.

4.  **Feature Fusion:**Â Concatenates Graph Embeddings with Global System Features (Temperature, Pressure, etc.).

5.  **Temporal Encoding (Transformer):**

    -   **Positional Encoding:**Â Injects time-step order information.

    -   **Transformer Encoder:**Â 3-Layer Multi-Head Self-Attention mechanism to learn trajectory dynamics.

6.  **Readout:**Â Regression head predictsÂ $\Delta G$Â based on the final state of the sequence.

ğŸ“‚ Data Requirements
--------------------

The script expects three CSV files in the root directory.

### 1\.Â `protein_graph_nodes_...csv`

Contains atomic features.

-   **Required Columns:**Â `frame`,Â `atom_index`,Â `Z`Â (Atomic Number),Â `mass`,Â `rmsd`,Â `rmsf`,Â `element`Â (categorical),Â `chain`(categorical).

### 2\.Â `protein_graph_edges_...csv`

Contains bond/interaction features.

-   **Required Columns:**Â `frame`,Â `atom_i`,Â `atom_j`,Â `bond_type`Â (categorical),Â `distance`,Â `angle`Â (degrees).

-   *Note:*Â The code automatically convertsÂ `angle`Â intoÂ `sin(angle)`Â andÂ `cos(angle)`Â components.

### 3\.Â `protein_graph_global_...csv`

Contains system-wide variables.

-   **Required Columns:**Â `frame`, plus any global features (e.g.,Â `Temperature`,Â `PotentialEnergy`,Â `GB_4`).

ğŸ› ï¸ Installation
----------------

Ensure you have a Python environment (3.8+) with the following dependencies:

```
# Core DL Libraries
pip install torch torchvision
pip install torch-geometric

# Data Handling & Math
pip install pandas numpy scikit-learn

# Plotting
pip install matplotlib seaborn

```

*Note: ForÂ `torch-geometric`, ensure you install the scatter/sparse binaries matching your CUDA version.*

ğŸš€ Usage
--------

1.  **Configure Paths:**Â Open the script and edit the file paths in theÂ `MAIN EXECUTION`Â section:

    ```
    edge_file = 'path/to/edges.csv'
    node_file = 'path/to/nodes.csv'
    graph_file = 'path/to/global.csv'

    ```

2.  **Set Target:**Â Define your experimentalÂ $\Delta G$Â value:

    ```
    EXPERIMENTAL_DELTA_G = -10667.0

    ```

3.  **Run the Training:**

    ```
    python model_training.py

    ```

### Hyperparameters

Key parameters can be adjusted at the top of theÂ `MAIN EXECUTION`Â block:

-   `WINDOW_SIZE`: Number of frames to look back (default: 5).

-   `HIDDEN_DIM`: Dimension of internal embeddings (default: 128).

-   `TRANSFORMER_LAYERS`: Depth of the temporal encoder (default: 3).

-   `WARMUP_EPOCHS`: Epochs to ignore for model saving (default: 20).

ğŸ“Š Outputs & Visualization
--------------------------

Upon completion, the script creates aÂ `results_plots/`Â directory containing:

1.  **`trajectory_dg.png`**: A time-series plot comparing Predicted vs. ExperimentalÂ $\Delta G$Â across the test trajectory.

2.  **`parity_plot.png`**: Scatter plot showing correlation ($R^2$Â and RMSE) between ground truth and predictions.

3.  **`loss_curve.png`**: Training and Validation RMSE evolution over epochs.

4.  **`error_distribution.png`**: Histogram of residual errors.

The script also saves the best model weights toÂ `best_model_dg.pth`.

ğŸ”¬ Feature Engineering Details
------------------------------

-   **Angle Transformation:**Â Raw angles (degrees) are automatically converted to cyclic encodings ($\sin(\theta), \cos(\theta)$) to preserve geometric continuity.

-   **Scaling:**Â * Node/Edge/Global features are scaled usingÂ `StandardScaler`.

    -   The TargetÂ $\Delta G$Â is scaled by a factor of 1000.0 for numerical stability during backpropagation.

-   **Tokenization:**Â Each frame in the window is treated as a "token" in the Transformer sequence, analogous to words in an NLP sentence.

ğŸ“œ License
----------

[MIT License](https://www.google.com/search?q=LICENSE "null")
